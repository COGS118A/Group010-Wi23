{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like mtcars, iris, palmer penguins etc.\n",
    "- The dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training a supervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your ML system.\n",
    "- You will evaluate the performance of your ML system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer Review\n",
    "\n",
    "You will all have an opportunity to look at the Project Proposals of other groups to fuel your creativity and get more ideas for how you can improve your own projects. \n",
    "\n",
    "Both the project proposal and project checkpoint will have peer review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Sidney Ma\n",
    "- Sean Rote\n",
    "- Sarah Horne\n",
    "- Kevin Su\n",
    "- Zhetai (Jack) Zhou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "In this age, music has become an important part of people’s lives and an incredibly important part of their individuality, so why are our music recommendation systems based on the data from other users? Our research focuses on Spotify, a popular Swedish music service. Spotify currently uses other users' data to suggest songs to users with similar music tastes. We want to create a new algorithm that would focus on the content and composition of songs to recommend objectively similar songs to users. This algorithm could be extended in order to take in any song, form any music platform, and find a similar song within Spotify's database. We plan to utilize K-nearest neighbors in order to find similar songs based on a variety of features, such as key signature. The success of our algorithm will be determined by the objective similarity between songs. Additionally, the researchers will listen to both songs and determine if they are similar, but this data would have little external validity. Further research could be done to increase this validity and evaluate whether the algorithm would have better performance if actually implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "A plethora of research has gone into recommendation algorithms, picking apart every pro and con of the incredibly common mechanism. Research into these algorithms doesn’t converge to provide one technique as the most effective or efficient. Our research plans to specifically place emphasis on Spotify, the incredibly popular Swedish music service. Spotify’s current algorithm pulls from other users data to compare what users with similar music preferences listen to. This recommendation system is called “collaborative filtering”. “If user A has enjoyed songs X, Y and Z, and user B has enjoyed songs X and Y (but haven't heard Z yet), we should recommend song Z to them.”[<sup>1</sup>](#fn1) Whether or not someone has “enjoyed” listening to a song is determined by their interactions with it. In Spotify's algorithm, listening to a song for more than 30 seconds is considered enjoying the song. Additionally, they also look at what songs users are ‘liking’ and adding to their playlists[<sup>2</sup>](#fn2)\n",
    "\n",
    "This algorithm greatly relies on spotify’s ability to gather data from their customers, which is incredibly expensive and could be considered a breach of privacy on behalf of their customers.[<sup>2</sup>](#fn2) The latter doesn’t tend to e a point a contention among spotify customers, since their data is later packaged to them in the form of a yearly recap. Another issue is that the algorithm lacks the ability to adapt to new music and makes it difficult for new artists to break out.[<sup>3</sup>](#fn3)  This problem similarly extends to new spotify users who have little data for the algorithm to pull from for its recommendation. This issue would likely still be present in our proposed system, since all recommendation algorithms will have to utilize some kind of user data.\n",
    "\n",
    "Instead, if we could create a new algorithm that focused on the content of songs, we may be able to use machine learning to create a cheaper, better system. This system would focus on quantifying different aspects of songs and finding similar songs to recommend to users. We have chosen our style of recommendation system in hopes that it can be further applied to take input data from outside sources. In theory, any music, from other sites, such as youtube, could be fed into the algorithm, and based on the aspects of the song, the algorithm could provide a recommendation from spotify’s database of songs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "As we stated above, the current song recommendation doesn’t objectively rely on the similarity of the songs but similar users’ listening patterns. The purpose of our project is to identify the most similar songs to the current song the user is listening to, hence creating a better recommendation algorithm for spotify recommended songs. We will focus on more technical features of the song itself instead of a similar user’s listening pattern. Our objective is to find the best regression algorithm which generates the most similar songs through the features we provide to it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "There is no shortage of Spotify data that can be found online. For the time being, we will be working with four datasets found on Kaggle.com:\n",
    "\n",
    "1: Dataset of songs in Spotify\n",
    "- Link: https://www.kaggle.com/datasets/mrmorj/dataset-of-songs-in-spotify\n",
    "- 1.2 million rows, 24 columns\n",
    "- Each row includes objective information about the song (tempo, length, etc.), subjective information (danceability, energy, etc.), genre, and more.\n",
    "- At a glance, this dataset seems to be somewhat partial to EDM and hip hop.\n",
    "\n",
    "2: Spotify Tracks Dataset\n",
    "- Link: https://www.kaggle.com/datasets/maharshipandya/-spotify-tracks-dataset\n",
    "- ~90,000 rows, 20 columns\n",
    "- Each row includes most of the information listed in dataset 1.\n",
    "- This dataset includes over 125 genres.\n",
    "\n",
    "3: Spotify Million Song Dataset\n",
    "- Link: https://www.kaggle.com/datasets/notshrirang/spotify-million-song-dataset\n",
    "- ~60,000 rows (not one million!), 4 columns\n",
    "- Each row includes the artist, title, link (unique to each row) and lyrics.\n",
    "- At a glance, this dataset seems to be mostly pop.\n",
    "\n",
    "4: Spotify and Genius Track Dataset\n",
    "- Link: https://www.kaggle.com/datasets/saurabhshahane/spotgen-music-dataset \n",
    "- The link includes several datasets, some of which are probably unimportant for our project.\n",
    "- spotify_artists.csv has ~56,000 rows, 9 columns.\n",
    "- spotify_tracks.csv has ~100,000 rows, 32 columns\n",
    "- As far as we can tell, this dataset does not include that much information about lyrical analysis, but it would help to have another source that examines the lyrics of many songs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "We will utilize the datasets of spotify on Kaggle that were extracted through Spotify API and we will determine a fix set of features for anaylyzing and representing a song. \n",
    "The main regression algorithm we are going to use for now is KNN algorithm. First, we will decide what is the best set of features to determine the similarity of the songs. The datasets provided us various types of features such as dancibility, loudness, key, and livenss, etc. As some features may not be as representative as other features, it’s important to select the most indicative features to feed into our algorithm. We also will need to select the most optimal hyperparameter for the KNN algorithm. As we running the algorithm, we want to make sure that both generalization error and testing error will be minimized. So as we enter the featured data of our selected song, the algorithm will provide us the K most similared songs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "The evaluation metric that we could use would be precision and recall methods. We could use precision to measure the proportion of recommended songs that a user would find relevant, while we could then use recall to measure the amount of relevant songs that are correctly recommended by the algorithm. The mathematical representation could go as follows: Precision = (Number of “relevant recommended songs”) / (Total number of recommended songs) and Recall = (Number of relevant songs) / (Total number of relevant songs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a variety of ethical issues to consider, including privacy concerns, managing dataset bias, avoiding unreasonable conclusions, and setting realistic expectations as to what our tool will be capable of.\n",
    "\n",
    "Privacy concerns will probably be the easiest to manage. In order to avoid privacy breaches, it is important for us to make sure that the data we work with does not cross into personal user information. So far, the datasets we have gathered do not contain any user information, but since Spotify does collect information about users, it’s very possible that some datasets we come across in the future will require us to deal with this. If this is the case, we will be sure to remove the information in our data cleaning process.\n",
    "\n",
    "Dataset bias will be a significant issue to consider. Because we are planning to make a tool to be used by all music listeners, we would ideally want it to be equally useful for everyone. However, if our model is trained on certain genres of music more than others, it will obviously be much better at finding similar music and avoiding dissimilar music only in those specific genres. This is an especially important issue to consider in terms of equality – since different demographics of people tend to listen to different genres, it is important to make sure that our tool does not favor one demographic over another. To avoid this, our best and most simple option is to search for a wide variety of genres and make sure that there is a sufficient amount of data points for each one.\n",
    "\n",
    "It is also important that the findings we come across in our project do not lead to erroneous conclusions. For instance, if we find that our tool is much better at finding similar hip hop songs than it is at finding similar EDM songs, we would not take this to mean that hip hop is simply “less diverse” than EDM – the result might just have to do with the limited dataset our model has been trained on. It is not only important that we don’t justify unreasonable conclusions in our paper, but also important to be clear enough that readers would not come to these conclusions either.\n",
    "    \n",
    "We should make it clear in our paper what our tool should be expected to do, and be very clear about its many limitations. For instance, our tool will obviously not work on every single song and every single audio file – there are probably many songs that our tool will not be able to relate. At the same time, we should make sure that our tool is significantly useful (for example, simply recommending other songs by the same artist might lead to satisfactory results, but would not be very interesting).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "- Team members will meet at least once a week\n",
    "- Team members should be responsive in the team group chat\n",
    "- Aim to finish assignments at least 24 hours before the deadline\n",
    "- If a team member misses a meeting we will set up a set time to fill them in\n",
    "- If conflict should arise we should resolve through group communication\n",
    "- Workload expectation for the group is assumed equal load among each other\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Date  | Time   | Agenda  | Goal |\n",
    "|---|---|---|---|\n",
    "| 2/21  |  2 PM |  Peer reviews of proposal  | Finish the proposal and ready for turning in | \n",
    "| 2/27  |  4 PM |  Assign jobs to each team member | Have dataset cleaning done and plan for out exploratory data analysis | \n",
    "| 3/6  | 3 PM  | Discuss EDA progress and brainstorm for any roadblock  | Continue to prepare our analysis and make the observation understandable by using metrics   |\n",
    "| 3/13  | 3 PM  | Discuss the progress of the entire project, see what is still missing | Complete the analysis and begin to draft our conclusion and report   |\n",
    "| 3/23  | 12 PM  | Discuss the progress of the entire project, see what is still missing | Complete the analysis and begin to draft our conclusion and report |\n",
    "| 3/20  | 11 AM  | Each team member demonstrate their part, and complete the group report| Finish up the report |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<span id=\"fn1\">1: https://www.music-tomorrow.com/blog/how-spotify-recommendation-system-works-a-complete-guide-2022 </span>\n",
    "\n",
    "<span id=\"fn2\">2: https://towardsdatascience.com/uncovering-how-the-spotify-algorithm-works-4d3c021ebc0 </span>\n",
    "\n",
    "<span id=\"fn3\">3: https://link.springer.com/chapter/10.1007/978-981-13-7403-6_26 </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
